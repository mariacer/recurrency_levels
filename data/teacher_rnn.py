#!/usr/bin/env python3
# Copyright 2020 Christian Henning
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# @title          :data/teacher_rnn.py
# @author         :ch
# @contact        :henningc@ethz.ch
# @created        :07/16/2020
# @version        :1.0
# @python_version :3.6.10
r"""
Dataset from random recurrent teacher networks
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We consider a student-teacher setup, where a synthetic dataset is generated by
the teacher and needs to be learned by a student network.

To be more precise, we set the teacher to be an Elman-type recurrent network
(see :class:`networks.RNN`):

.. math::

    r_t = \sigma (A r_{t-1} + x_t) \\
    s_t = \sigma (B r_t) \\
    t_t = C s_t}

Where :math:`x_t` is the network input at time :math:`t`, the recurrent
state is initialized at zero :math:`r_0 = 0` and :math:`\sigma()` is a
user-defined non-linearity. The non-linear output computation :math:`s_t`
is optional.

We assume an input :math:`x_t \in \mathbb{R}^{n_\text{in}}` and a target
dimensionality of :math:`n_\text{out}`.
:math:`A \in \mathbb{R}^{n_\text{in} \times n_\text{in}}`,
:math:`B \in \mathbb{R}^{n_\text{in} \times n_\text{in}}` and
:math:`C \in \mathbb{R}^{n_\text{out} \times n_\text{in}}` are random
matrices that determine the teacher network's input-output mapping.
"""
# Do not delete the following import for all executable scripts!
import __init__ # pylint: disable=unused-import

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import ortho_group
import torch
from warnings import warn

import bio_rnn.bio_utils as mc_utils
from data.sequential_dataset import SequentialDataset
import networks.net_utils as nu

class RndRecTeacher(SequentialDataset):
    r"""Create a dataset from a random recurrent teacher.

    Attributes:
        mat_A (numpy.ndarray): The teacher matrix :math:`A`.
        mat_B (numpy.ndarray): The teacher matrix :math:`B`.
        mat_C (numpy.ndarray): The teacher matrix :math:`C`.

    Args:
        num_train (int): Number of training samples.
        num_test (int): Number of test samples.
        num_val (int, optional): Number of validation samples.
        n_in (int): Dimensionality of inputs :math:`x_t`.
        n_out (int): Dimensionality of outputs :math:`y_t^{(k)}`.
        sigma (str): Name of the nonlinearity :math:`\sigma()` to be used.

            - ``'linear'``
            - ``'sigmoid'``
            - ``'tanh'``
        mat_A (numpy.ndarray, optional): A numpy array of shape
            ``[n_in, n_in]`` representing matrix :math:`A`. If not
            specified, a random matrix will be generated.
        mat_B (numpy.ndarray, optional): A numpy array of shape
            ``[n_in, n_in]`` representing matrix :math:`B`. If not
            specified, a random matrix will be generated.
        mat_C (numpy.ndarray, optional): A numpy array of shape
            ``[n_out, n_in]`` representing matrix :math:`C`. If not
            specified, a random matrix will be generated.
        orth_A (bool): If :math:`A` is randomly generated and this option
            is activated, then :math:`A` will be initialized as an
            orthogonal matrix.
        rank_A (int, optional): The rank of the randomly generated matrix
            :math:`A`. Note, this option is mutually exclusive with
            option ``orth_A``.
        max_sv_A (float, optional): The maximum singular value of the randomly
            generated matrix :math:`A`. Note, this option is mutually
            exclusive with option ``orth_A``.
        no_extra_fc: If ``True``, the hidden fully-connected layer using matrix
            :math:`B` will be omitted when computed targets from the
            teacher. Hence, the teacher computation becomes:

            .. math::

                r_t = \sigma (A r_{t-1} + x_t) \\
                t_t = C r_t
        inputs (numpy.ndarray, optional): The inputs :math:`x_t` to be used.
            Has to be an array of shape ``[n_ts_in, N, n_in]`` with
            ``N = num_train + num_test + (0 if num_val is None else num_val)``.
        input_range (tuple): Tuple of integers. Used as ranges for a uniform
            distribution from which input samples :math:`x_t` are drawn.
        n_ts_in (int): The number of input timesteps.
        n_ts_out (int, optional): The number of output timesteps. Can be greater
            than ``n_ts_in``. In this case, the inputs at time greater than
            ``n_ts_in`` will be zero.
        rseed (int, optional): If ``None``, the current random state of numpy
            is used to generate the data. Otherwise, a new random state with the
            given seed is generated.
    """
    def __init__(self, config, input_range=(-1, 1)):
        super().__init__()

        n_in = config.teacher_input_size
        n_out = config.teacher_output_size
        num_train = config.teacher_num_train
        num_val = config.teacher_num_val
        num_test = config.teacher_num_test
        n_ts_in = config.teacher_n_ts_in
        n_ts_out = config.teacher_n_ts_out

        if config.data_random_seed is not None:
            self._rstate = np.random.RandomState(config.data_random_seed)
        else:
            self._rstate = np.random

        self._n_in = n_in
        self._n_out = n_out

        ### Create inputs ###
        num_samples = num_train + num_test + (0 if num_val is None else num_val)
        inputs = self._rstate.uniform(low=input_range[0],
            high=input_range[1], size=(n_ts_in, num_samples, n_in))

        assert n_ts_out == -1 or n_ts_out >= n_ts_in
        if n_ts_out > n_ts_in:
            inputs = np.concatenate((inputs,
                np.zeros((n_ts_out-n_ts_in, num_samples, n_in))), axis=0)

        ### Create teacher_network
        teacher_rnn = generate_teacher_network(config, device='cpu',
                                               rseed=config.data_random_seed)
        self.teacher_rnn = teacher_rnn

        ### Compute targets ###
        # Forward function requires torch.Tensors to function.
        targets = teacher_rnn.forward(torch.tensor(inputs, dtype=torch.float32))

        ### Setup dataset ###
        self._data['classification'] = False
        self._data['is_one_hot'] = False
        self._data['sequence'] = True
        self._data['in_shape'] = [n_in]
        self._data['out_shape'] = [n_out]
        self._data['train_inds'] = np.arange(num_train)
        self._data['test_inds'] = np.arange(num_train, num_train + num_test)
        if num_val is not None:
            n_start = num_train + num_test
            self._data['val_inds'] = np.arange(n_start, n_start + num_val)
        self._data['in_data'] = self._flatten_array(inputs, ts_dim_first=True)
        self._data['out_data'] = self._flatten_array(targets.detach().numpy(),
                                                     ts_dim_first=True)
        # Note, inputs and outputs have internally the same length, even though
        # inputs might be zero-padded.
        self._data['in_seq_lengths'] = np.ones(num_samples) * n_ts_in
        self._data['out_seq_lengths'] = np.ones(num_samples) * n_ts_out

        print('Constructed: ' + str(self))

    def _plot_config(self, inputs, outputs=None, predictions=None):
        """Defines properties, used by the method :meth:`plot_samples`.

        This method can be overwritten, if these configs need to be different
        for a certain dataset.

        Args:
            (....): See docstring of method
                :meth:`data.dataset.Dataset._plot_config`.

        Returns:
            (dict): A dictionary with the plot configs.
        """
        plot_configs = dict()
        plot_configs['outer_wspace'] = 0.1
        plot_configs['outer_hspace'] = 0.4
        plot_configs['inner_hspace'] = 0.2
        plot_configs['inner_wspace'] = 0.2
        plot_configs['num_inner_rows'] = 1
        if outputs is not None:
            plot_configs['num_inner_rows'] += 1
        if predictions is not None:
            plot_configs['num_inner_rows'] += 1
        plot_configs['num_inner_cols'] = 1
        plot_configs['num_inner_plots'] = plot_configs['num_inner_rows']

        return plot_configs

    def _plot_sample(self, fig, inner_grid, num_inner_plots, ind, inputs,
                     outputs=None, predictions=None, **kwargs):
        # Inputs.
        ax = plt.Subplot(fig, inner_grid[0])
        inputs = self._flatten_array(inputs, ts_dim_first=True, reverse=True,
                                     feature_shape=[self._n_in])
        ax.imshow(inputs[:, 0, :].T)
        #ax.set_xlabel('time')
        ax.set_xticks([])
        fig.add_subplot(ax)

        # Outputs.
        ax = plt.Subplot(fig, inner_grid[1])
        outputs = self._flatten_array(outputs, ts_dim_first=True, reverse=True,
                                     feature_shape=[self._n_out])
        ax.imshow(outputs[:, 0, :].T)
        fig.add_subplot(ax)

        # Predictions.
        ax = plt.Subplot(fig, inner_grid[2])
        predictions = self._flatten_array(predictions, ts_dim_first=True,
                                          reverse=True,
                                          feature_shape=[self._n_out])
        ax.imshow(predictions[:, 0, :].T)
        ax.set_xlabel('time')
        fig.add_subplot(ax)

    def get_identifier(self):
        """Returns the name of the dataset."""
        return 'Teacher network dataset'


def generate_teacher_network(config, device, rseed=None):
    """Create a teacher RNN network (Basically the same function as
    generate_network, only we use different config args to build the network.

    Args:
        config (argparse.Namespace): Command-line arguments.
        device: Torch device.
        rseed (None or int, optional): The random seed.

    Returns:
        An RNN instance.
    """
    if hasattr(config, 'teacher_use_rnn_microcircuit') and \
            config.teacher_use_rnn_microcircuit:
        ### Microcircuit RNN.
        net = mc_utils.generate_network(config, None, device,
                                        n_in=config.teacher_input_size,
                                        n_out=config.teacher_output_size, 
                                        is_teacher=True)
    else:
        ### Standard RNN.
        net = nu.generate_network(config, None, device, 
                                  n_in=config.teacher_input_size,
                                  n_out=config.teacher_output_size,
                                  is_teacher=True,
                                  rseed=rseed)
        
    return net


if __name__ == '__main__':
    pass
